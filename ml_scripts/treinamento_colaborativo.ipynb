{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac7fcca-bd96-4754-95ed-2105cfca2d1f",
   "metadata": {},
   "source": [
    "# IMPORTANDO BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94412623-27d8-4ec4-ad40-9b1988c26963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Bibliotecas carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a89a51-c900-4b84-9654-ca1e84a2b0ce",
   "metadata": {},
   "source": [
    "# Configuração, variáveis de ambiente e conexão com o banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d74be4-5b49-42f8-8727-ec7478b191f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o banco de dados criada com sucesso!\n",
      "Artefato será salvo em: modelo_colaborativo.pkl\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd()\n",
    "PATH_RATINGS = BASE_DIR / 'ratings.csv'\n",
    "PATH_LINKS = BASE_DIR / 'links.csv'\n",
    "ARTEFATO = 'modelo_colaborativo.pkl'\n",
    "\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "env_path = BASE_DIR.parent / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "DB_URL = f\"postgresql://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "\n",
    "try:\n",
    "    engine = create_engine(DB_URL)\n",
    "    print(\"Conexão com o banco de dados criada com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar com o banco: {e}\")\n",
    "\n",
    "print(f\"Artefato será salvo em: {ARTEFATO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5e982-d4d0-4835-9076-e68aea0836f2",
   "metadata": {},
   "source": [
    "# Carregando dados locais e do movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4d6c0-8f79-4c75-a196-2bbe607a8a9e",
   "metadata": {},
   "source": [
    "### Aqui fazemos o carregamento do MovieLens e do PostgreSQL. Aplicando o deslocamento (offset) de +1.000.000 nos IDs do MovieLens para evitar conflito com os IDs do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30d608f-3b27-4a8b-99b8-08d4b9a94459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO CARGA DE DADOS\n",
      "Total de filmes no catálogo: 9119\n",
      "Carregando MovieLens...\n",
      "MovieLens carregado: 51866 avaliações.\n",
      "(Removidas 48957 avaliações inúteis)\n",
      "Carregando dados locais do BD\n",
      "Avaliações carregadas: 61\n",
      "Carregando Favoritos do BD\n",
      "21 favoritos transformados em nota 5.0.\n",
      "Carga de dados concluída em 0.08s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"INICIANDO CARGA DE DADOS\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    query_filmes = \"SELECT tmdb_id FROM filmes\"\n",
    "    df_filmes_db = pd.read_sql(query_filmes, engine)\n",
    "    \n",
    "    ids_filmes_validos = set(df_filmes_db['tmdb_id'].unique())\n",
    "    print(f\"Total de filmes no catálogo: {len(ids_filmes_validos)}\")\n",
    "    \n",
    "    print(\"Carregando MovieLens...\")\n",
    "    df_ml_ratings = pd.read_csv(PATH_RATINGS)\n",
    "    df_ml_links = pd.read_csv(PATH_LINKS)\n",
    "\n",
    "    # Limpeza básica e Merge para pegar o tmdbId\n",
    "    df_ml_links = df_ml_links.dropna(subset=['tmdbId'])\n",
    "    df_ml_links['tmdbId'] = df_ml_links['tmdbId'].astype(int)\n",
    "    df_ml_full = df_ml_ratings.merge(df_ml_links, on='movieId')\n",
    "    df_ml_filtered = df_ml_full[df_ml_full['tmdbId'].isin(ids_filmes_validos)].copy()\n",
    "    \n",
    "    df_ml_final = df_ml_filtered[['userId', 'tmdbId', 'rating']].copy()\n",
    "    df_ml_final.columns = ['id_usuario', 'tmdb_id', 'nota']\n",
    "    \n",
    "    # Offset\n",
    "    df_ml_final['id_usuario'] = df_ml_final['id_usuario'] + 1000000 \n",
    "    print(f\"MovieLens carregado: {len(df_ml_final)} avaliações.\")\n",
    "    print(f\"(Removidas {len(df_ml_full) - len(df_ml_final)} avaliações inúteis)\")\n",
    "\n",
    "    # Postgresql\n",
    "    print(\"Carregando dados locais do BD\")\n",
    "    query_avaliacoes = \"\"\"\n",
    "        SELECT a.id_usuario, a.id_filme AS tmdb_id, a.nota\n",
    "        FROM avaliacoes a\n",
    "    \"\"\"\n",
    "    df_avaliacoes = pd.read_sql(query_avaliacoes, engine)\n",
    "    print(f\"Avaliações carregadas: {len(df_avaliacoes)}\")\n",
    "    \n",
    "    print(\"Carregando Favoritos do BD\")\n",
    "    query_favoritos = \"\"\"\n",
    "        SELECT fav.id_usuario, fav.id_filme AS tmdb_id\n",
    "        FROM favoritos fav\n",
    "    \"\"\"\n",
    "    df_favoritos = pd.read_sql(query_favoritos, engine)\n",
    "\n",
    "    if not df_favoritos.empty:\n",
    "        df_favoritos['nota'] = 5.0 \n",
    "        print(f\"{len(df_favoritos)} favoritos transformados em nota 5.0.\")\n",
    "    else:\n",
    "        df_favoritos = pd.DataFrame(columns=['id_usuario', 'tmdb_id', 'nota'])\n",
    "\n",
    "    print(f\"Carga de dados concluída em {time.time() - start_time:.2f}s\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"ERRO DURANTE O CARREGAMENTO DOS DADOS\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ffd419-2ffe-4ddf-bb36-ad84878677ee",
   "metadata": {},
   "source": [
    "# Processamento e junção dos dois datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8ee92-8b50-4a22-bd4e-a041ef6391ea",
   "metadata": {},
   "source": [
    "### União dos dois datasets em um único DataFrame para o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4929f220-48e0-4f94-a157-0036102fdb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundindo os datasets...\n",
      "Total de avaliações para treino: 51927\n",
      "Amostra dos dados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_usuario</th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>862</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>15602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>949</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_usuario  tmdb_id  nota\n",
       "0     1000001      862   4.0\n",
       "1     1000001    15602   4.0\n",
       "2     1000001      949   4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Fundindo os datasets...\")\n",
    "df_local = pd.concat([df_avaliacoes, df_favoritos], ignore_index=True)\n",
    "df_local = df_local.drop_duplicates(subset=['id_usuario', 'tmdb_id'], keep='first')\n",
    "df_total = pd.concat([df_ml_final, df_local], ignore_index=True)\n",
    "\n",
    "print(f\"Total de avaliações para treino: {len(df_total)}\")\n",
    "print(\"Amostra dos dados:\")\n",
    "display(df_total.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f8f62-a1b4-44a5-a215-5e246dded0ff",
   "metadata": {},
   "source": [
    "# TREINAMENTO DO MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd0821-21ad-4161-98d3-047f4eedcb81",
   "metadata": {},
   "source": [
    "### Configuração do Reader (escala de notas) e treinamento do algoritmo SVD. Incluí validação cruzada para visualizar a performance (RMSE) antes de treinar o final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4d02aee-9866-4015-943d-42b308ee764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO TREINAMENTO SVD\n",
      "Executando validação cruzada rápida (3-folds)...\n",
      "RMSE Médio estimado: 0.8569\n",
      "Treinando modelo com dataset completo...\n",
      "Modelo treinado em 1.54s\n"
     ]
    }
   ],
   "source": [
    "print(\"INICIANDO TREINAMENTO SVD\")\n",
    "start_train = time.time()\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df_total[['id_usuario', 'tmdb_id', 'nota']], reader)\n",
    "\n",
    "# validação cruzada\n",
    "print(\"Executando validação cruzada rápida (3-folds)...\")\n",
    "algo_test = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "cv_results = cross_validate(algo_test, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "print(f\"RMSE Médio estimado: {cv_results['test_rmse'].mean():.4f}\")\n",
    "\n",
    "# Treinamento com todos os dados\n",
    "print(\"Treinando modelo com dataset completo...\")\n",
    "trainset = data.build_full_trainset()\n",
    "modelo_final = algo_test\n",
    "modelo_final.fit(trainset)\n",
    "\n",
    "print(f\"Modelo treinado em {time.time() - start_train:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7178483-53d4-4417-9dcb-bc5616408aef",
   "metadata": {},
   "source": [
    "# SALVANDO ARTEFATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba440727-df0a-4b12-9537-1a63ad69f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando artefato do modelo...\n",
      "Modelo salvo em 'modelo_colaborativo.pkl' com sucesso.\n",
      "TREINAMENTO CONCLUÍDO!\n"
     ]
    }
   ],
   "source": [
    "print('Salvando artefato do modelo...')\n",
    "\n",
    "metadata = {\n",
    "    \"version\": \"1.4.0\",\n",
    "    \"date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"algorithm\": \"SVD\",\n",
    "    \"n_ratings\": len(df_total),\n",
    "    \"model\": modelo_final\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, ARTEFATO)\n",
    "\n",
    "print(f\"Modelo salvo em '{ARTEFATO}' com sucesso.\")\n",
    "print(\"TREINAMENTO CONCLUÍDO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929f5ea-1c7f-48f9-8886-eb06245065c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
